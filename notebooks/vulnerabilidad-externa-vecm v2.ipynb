{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7f501b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\anaconda3\\envs\\tftimeseriesII\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\Usuario\\anaconda3\\envs\\tftimeseriesII\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\Users\\Usuario\\anaconda3\\envs\\tftimeseriesII\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "from statsmodels.tsa.vector_ar.vecm import VECM\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "# Importaci√≥n robusta de coint_johansen y kpss\n",
    "try:\n",
    "    from statsmodels.tsa.vector_ar.util import coint_johansen\n",
    "except ImportError:\n",
    "    try:\n",
    "        from statsmodels.tsa.stattools import coint_johansen\n",
    "    except ImportError:\n",
    "        try:\n",
    "            from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "        except ImportError:\n",
    "            print(\"Warning: coint_johansen not found. Will implement basic cointegration test.\")\n",
    "            coint_johansen = None\n",
    "\n",
    "try:\n",
    "    from statsmodels.tsa.stattools import kpss\n",
    "except ImportError:\n",
    "    print(\"Warning: kpss not available in this statsmodels version\")\n",
    "    kpss = None\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de gr√°ficos\n",
    "plt.style.use('default')\n",
    "try:\n",
    "    sns.set_palette(\"husl\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# DataFrame indicadores\n",
    "df_indicadores = pd.read_csv('../data/indicadores/indicadores_macroeconomicos.csv',\n",
    "                             sep=';', encoding='latin1')\n",
    "df_indicadores = df_indicadores.set_index('fecha')\n",
    "# CONVERTIR EL √çNDICE A STRING\n",
    "df_indicadores.index = df_indicadores.index.astype(str)\n",
    "df_indicadores.index.name = 'fecha'\n",
    "\n",
    "# DataFrame termotrade  \n",
    "df_termotrade = pd.read_csv('../data/indicadores/monthly_results_brazil.csv', \n",
    "                            sep=\";\", encoding='latin1')\n",
    "df_termotrade = df_termotrade[['date', 'ctot_level']]\n",
    "df_termotrade = df_termotrade.rename(columns={'ctot_level': 'termoftrade'})\n",
    "df_termotrade = df_termotrade.set_index('date')\n",
    "df_termotrade.index = pd.to_datetime(df_termotrade.index).strftime('%Y%m')\n",
    "df_termotrade.index.name = 'fecha'\n",
    "\n",
    "\n",
    "# Hacer el merge de los dos DataFrames\n",
    "df_combined = df_indicadores.join(df_termotrade, how='outer')\n",
    "\n",
    "# ==============================================================================\n",
    "# A√ëADIR VARIABLE DUMMY PARA LA PANDEMIA (Marzo 2020 - Septiembre 2020)\n",
    "# ==============================================================================\n",
    "\n",
    "# 1. Crear la columna 'pandemia_dummy' y llenarla con ceros\n",
    "df_combined['pandemia_dummy'] = 0\n",
    "\n",
    "# 2. Asignar el valor 1 para el per√≠odo especificado\n",
    "# Usamos .loc para seleccionar las filas por el √≠ndice (fecha)\n",
    "start_date = '202003'\n",
    "end_date = '202009'\n",
    "df_combined.loc[start_date:end_date, 'pandemia_dummy'] = 1\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# A√ëADIR VARIABLE PIB DE BRASIL\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "gdp_brazil = pd.read_csv('../data/QGDP/brazil.csv', sep =\",\", encoding='latin1')\n",
    "gdp_brazil = gdp_brazil.set_index(gdp_brazil.columns[0])\n",
    "gdp_brazil.index = pd.to_datetime(gdp_brazil.index).strftime('%Y%m')  # String YYYYMM\n",
    "\n",
    "gdp_brazil = gdp_brazil.rename(columns={gdp_brazil.columns[0]: 'GDP_BRAZIL'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92b28d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "üîç PASO 1: CONSOLIDACI√ìN DE DATOS\n",
      "==================================================\n",
      "\n",
      "üîÑ APLICANDO TRANSFORMACIONES:\n",
      "  PIB Brasil: log transformation\n",
      "  Otros indicadores: normalizaci√≥n (Œº=0, œÉ=1)\n",
      "  termoftrade: Œº=100.592 ‚Üí 0, œÉ=0.803 ‚Üí 1\n",
      "  PI_USA: Œº=97.239 ‚Üí 0, œÉ=5.035 ‚Üí 1\n",
      "  PI_FRA: Œº=105.554 ‚Üí 0, œÉ=6.657 ‚Üí 1\n",
      "  PI_GER: Œº=96.813 ‚Üí 0, œÉ=8.000 ‚Üí 1\n",
      "  PI_ITA: Œº=105.058 ‚Üí 0, œÉ=11.543 ‚Üí 1\n",
      "  PI_UK: Œº=93.613 ‚Üí 0, œÉ=7.838 ‚Üí 1\n",
      "  DGS10: Œº=3.269 ‚Üí 0, œÉ=1.290 ‚Üí 1\n",
      "  SPREAD_USA: Œº=5.464 ‚Üí 0, œÉ=2.609 ‚Üí 1\n",
      "\n",
      "‚úÖ Dataset consolidado: (99, 18)\n",
      "üìÖ Per√≠odo: 200004-202410\n",
      "üî¢ Variables: ['GDP_BRAZIL', 'termoftrade', 'PI_USA', 'PI_FRA', 'PI_GER', 'PI_ITA', 'PI_UK', 'DGS10', 'SPREAD_USA', 'log_gdp_brazil', 'termoftrade_norm', 'PI_USA_norm', 'PI_FRA_norm', 'PI_GER_norm', 'PI_ITA_norm', 'PI_UK_norm', 'DGS10_norm', 'SPREAD_USA_norm']\n",
      "\n",
      "üìä Primeras observaciones:\n",
      "        GDP_BRAZIL  termoftrade   PI_USA  PI_FRA  PI_GER  PI_ITA  PI_UK  \\\n",
      "200004    194948.4    99.941465  92.6659   110.5    84.8   121.3   77.1   \n",
      "200007    197616.2    99.846339  92.8373   111.7    86.4   121.0   77.5   \n",
      "200010    199860.6    99.726163  92.6400   112.2    86.7   122.4   78.7   \n",
      "200101    200333.4    99.744042  91.8908   112.5    87.2   122.2   80.1   \n",
      "200104    199596.3    99.773005  90.7384   111.9    86.0   120.1   80.7   \n",
      "\n",
      "           DGS10  SPREAD_USA  log_gdp_brazil  termoftrade_norm  PI_USA_norm  \\\n",
      "200004  5.990526    5.847381       12.180490         -0.810299    -0.908351   \n",
      "200007  6.054000    6.123333       12.194082         -0.928760    -0.874309   \n",
      "200010  5.738571    7.292273       12.205375         -1.078414    -0.913496   \n",
      "200101  5.160952    8.497826       12.207738         -1.056149    -1.062298   \n",
      "200104  5.141000    8.496667       12.204052         -1.020082    -1.291182   \n",
      "\n",
      "        PI_FRA_norm  PI_GER_norm  PI_ITA_norm  PI_UK_norm  DGS10_norm  \\\n",
      "200004     0.743027    -1.501551     1.407099   -2.106910    2.110727   \n",
      "200007     0.923284    -1.301563     1.381109   -2.055874    2.159950   \n",
      "200010     0.998391    -1.264066     1.502393   -1.902766    1.915341   \n",
      "200101     1.043455    -1.201569     1.485067   -1.724140    1.467409   \n",
      "200104     0.953327    -1.351560     1.303141   -1.647586    1.451936   \n",
      "\n",
      "        SPREAD_USA_norm  \n",
      "200004         0.147044  \n",
      "200007         0.252832  \n",
      "200010         0.700950  \n",
      "200101         1.163105  \n",
      "200104         1.162660  \n"
     ]
    }
   ],
   "source": [
    "# PASO 1: CONSOLIDACI√ìN DE DATOS (SIMPLIFICADO)\n",
    "print(\"=\"*50)\n",
    "print(\"üîç PASO 1: CONSOLIDACI√ìN DE DATOS\")\n",
    "print(\"=\"*50)\n",
    "# Dataset final usando PIB como base (trimestral)\n",
    "df_model = gdp_brazil.copy()\n",
    "df_model = df_model.join(df_termotrade, how='inner')\n",
    "df_model = df_model.join(df_indicadores, how='inner')\n",
    "\n",
    "# NORMALIZACI√ìN: PIB en logs, resto estandarizado (media=0, std=1)\n",
    "print(f\"\\nüîÑ APLICANDO TRANSFORMACIONES:\")\n",
    "print(f\"  PIB Brasil: log transformation\")\n",
    "print(f\"  Otros indicadores: normalizaci√≥n (Œº=0, œÉ=1)\")\n",
    "\n",
    "# PIB en logs\n",
    "df_model['log_gdp_brazil'] = np.log(df_model['GDP_BRAZIL'])\n",
    "\n",
    "# Normalizar el resto de variables (excepto PIB)\n",
    "variables_to_normalize = [col for col in df_model.columns if col != 'GDP_BRAZIL' and col != 'log_gdp_brazil']\n",
    "\n",
    "for var in variables_to_normalize:\n",
    "    mean_val = df_model[var].mean()\n",
    "    std_val = df_model[var].std()\n",
    "    df_model[f'{var}_norm'] = (df_model[var] - mean_val) / std_val\n",
    "    print(f\"  {var}: Œº={mean_val:.3f} ‚Üí 0, œÉ={std_val:.3f} ‚Üí 1\")\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset consolidado: {df_model.shape}\")\n",
    "print(f\"üìÖ Per√≠odo: {df_model.index.min()}-{df_model.index.max()}\")\n",
    "print(f\"üî¢ Variables: {list(df_model.columns)}\")\n",
    "print(\"\\nüìä Primeras observaciones:\")\n",
    "print(df_model.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd02264f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "üìä PASO 2: VARIABLES DEL MODELO (PONDERADO)\n",
      "==================================================\n",
      "‚úÖ Variables creadas (IP_G7 ponderado): ['log_gdp_brazil', 'log_tot_brazil', 'log_ip_g7', 'us_10y', 'risk_spread']\n",
      "üìä Observaciones: 99\n",
      "üìÖ Per√≠odo final: 200004-202410\n",
      "\n",
      "üìà Estad√≠sticas descriptivas:\n",
      "       log_gdp_brazil  log_tot_brazil  log_ip_g7  us_10y  risk_spread\n",
      "count          99.000          99.000     99.000  99.000       99.000\n",
      "mean           12.504           4.611      4.593   3.269        5.464\n",
      "std             0.161           0.008      0.048   1.290        2.609\n",
      "min            12.180           4.595      4.327   0.624        2.740\n",
      "25%            12.368           4.604      4.570   2.225        3.653\n",
      "50%            12.581           4.608      4.600   3.388        4.663\n",
      "75%            12.623           4.618      4.616   4.270        6.487\n",
      "max            12.729           4.634      4.672   6.054       16.788\n"
     ]
    }
   ],
   "source": [
    "# PASO 2: VARIABLES DEL MODELO VECM (VERSI√ìN CORREGIDA)\n",
    "print(\"=\"*50)\n",
    "print(\"üìä PASO 2: VARIABLES DEL MODELO (PONDERADO)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Variables principales siguiendo metodolog√≠a Talvi et al.\n",
    "df_vecm = pd.DataFrame(index=df_model.index)\n",
    "\n",
    "df_vecm['log_gdp_brazil'] = np.log(df_model['GDP_BRAZIL'])\n",
    "df_vecm['log_tot_brazil'] = np.log(df_model['termoftrade'])  # posible quitar el logaritmo si no es necesario\n",
    "\n",
    "# IP_G7 con ponderaci√≥n espec√≠fica\n",
    "df_vecm['log_ip_g7'] = np.log(df_model['PI_USA'] * 0.40 + \n",
    "                              df_model['PI_FRA'] * 0.15 + \n",
    "                              df_model['PI_GER'] * 0.20 + \n",
    "                              df_model['PI_ITA'] * 0.12 + \n",
    "                              df_model['PI_UK'] * 0.13)\n",
    "\n",
    "df_vecm['us_10y'] = df_model['DGS10']\n",
    "df_vecm['risk_spread'] = df_model['SPREAD_USA']\n",
    "\n",
    "# Limpiar datos\n",
    "df_vecm = df_vecm.dropna()\n",
    "\n",
    "print(f\"‚úÖ Variables creadas (IP_G7 ponderado): {list(df_vecm.columns)}\")\n",
    "print(f\"üìä Observaciones: {len(df_vecm)}\")\n",
    "print(f\"üìÖ Per√≠odo final: {df_vecm.index.min()}-{df_vecm.index.max()}\")\n",
    "print(f\"\\nüìà Estad√≠sticas descriptivas:\")\n",
    "print(df_vecm.describe().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52e2fc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "üîç PASO 3: TESTS ECONOM√âTRICOS\n",
      "==================================================\n",
      "üìä TESTS DE RA√çCES UNITARIAS (NIVELES):\n",
      "log_gdp_brazil      : p-val=0.4997 -> No Estacionaria\n",
      "log_tot_brazil      : p-val=0.1235 -> No Estacionaria\n",
      "log_ip_g7           : p-val=0.0000 -> Estacionaria\n",
      "us_10y              : p-val=0.1668 -> No Estacionaria\n",
      "risk_spread         : p-val=0.0106 -> Estacionaria\n",
      "\n",
      "üìä TESTS EN PRIMERAS DIFERENCIAS:\n",
      "d_log_gdp_brazil     : p-val=0.0000 -> Estacionaria\n",
      "d_log_tot_brazil     : p-val=0.0000 -> Estacionaria\n",
      "d_log_ip_g7          : p-val=0.0000 -> Estacionaria\n",
      "d_us_10y             : p-val=0.0000 -> Estacionaria\n",
      "d_risk_spread        : p-val=0.0000 -> Estacionaria\n",
      "\n",
      "üìã RESUMEN DE ESTACIONARIEDAD:\n",
      "----------------------------------------------------------------------\n",
      "Variable             Nivel p-val  Diff p-val   Orden   \n",
      "----------------------------------------------------------------------\n",
      "log_gdp_brazil       0.4997       0.0000       I(1)    \n",
      "log_tot_brazil       0.1235       0.0000       I(1)    \n",
      "log_ip_g7            0.0000       0.0000       I(0)    \n",
      "us_10y               0.1668       0.0000       I(1)    \n",
      "risk_spread          0.0106       0.0000       I(0)    \n",
      "\n",
      "üîç VERIFICACI√ìN PARA VECM:\n",
      "Variables I(1): 3/5\n",
      "‚úÖ Condiciones cumplidas para VECM (‚â•2 variables I(1))\n"
     ]
    }
   ],
   "source": [
    "# PASO 3: TESTS DE RA√çCES UNITARIAS\n",
    "print(\"=\"*50)\n",
    "print(\"üîç PASO 3: TESTS ECONOM√âTRICOS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def test_unit_root(series, name):\n",
    "    \"\"\"Test ADF para ra√≠ces unitarias\"\"\"\n",
    "    try:\n",
    "        adf_result = adfuller(series.dropna())\n",
    "        adf_stat = adf_result[0]\n",
    "        adf_pval = adf_result[1]\n",
    "        result = \"No Estacionaria\" if adf_pval > 0.05 else \"Estacionaria\"\n",
    "        return {\n",
    "            'variable': name, \n",
    "            'adf_stat': adf_stat, \n",
    "            'p_value': adf_pval, \n",
    "            'result': result\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error en {name}: {e}\")\n",
    "        return {\n",
    "            'variable': name, \n",
    "            'adf_stat': np.nan, \n",
    "            'p_value': np.nan, \n",
    "            'result': 'Error'\n",
    "        }\n",
    "\n",
    "# Tests en niveles\n",
    "print(\"üìä TESTS DE RA√çCES UNITARIAS (NIVELES):\")\n",
    "unit_root_results = []\n",
    "for col in df_vecm.columns:\n",
    "    result = test_unit_root(df_vecm[col], col)\n",
    "    unit_root_results.append(result)\n",
    "    print(f\"{col:<20}: p-val={result['p_value']:.4f} -> {result['result']}\")\n",
    "\n",
    "# Tests en primeras diferencias\n",
    "print(\"\\nüìä TESTS EN PRIMERAS DIFERENCIAS:\")\n",
    "diff_results = []\n",
    "for col in df_vecm.columns:\n",
    "    diff_series = df_vecm[col].diff().dropna()\n",
    "    result = test_unit_root(diff_series, f\"d_{col}\")\n",
    "    diff_results.append(result)\n",
    "    print(f\"d_{col:<19}: p-val={result['p_value']:.4f} -> {result['result']}\")\n",
    "\n",
    "# Tabla resumen corregida\n",
    "print(\"\\nüìã RESUMEN DE ESTACIONARIEDAD:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Variable':<20} {'Nivel p-val':<12} {'Diff p-val':<12} {'Orden':<8}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for i, col in enumerate(df_vecm.columns):\n",
    "    nivel_pval = unit_root_results[i]['p_value']\n",
    "    diff_pval = diff_results[i]['p_value']\n",
    "    \n",
    "    # Determinar orden de integraci√≥n\n",
    "    if not np.isnan(nivel_pval) and not np.isnan(diff_pval):\n",
    "        if nivel_pval < 0.05:\n",
    "            orden = \"I(0)\"\n",
    "        elif diff_pval < 0.05:\n",
    "            orden = \"I(1)\"\n",
    "        else:\n",
    "            orden = \"I(2)+\"\n",
    "    else:\n",
    "        orden = \"Error\"\n",
    "    \n",
    "    print(f\"{col:<20} {nivel_pval:<12.4f} {diff_pval:<12.4f} {orden:<8}\")\n",
    "\n",
    "# Verificar condiciones para VECM\n",
    "print(\"\\nüîç VERIFICACI√ìN PARA VECM:\")\n",
    "i1_count = sum(1 for i in range(len(df_vecm.columns)) \n",
    "               if not np.isnan(unit_root_results[i]['p_value']) and \n",
    "                  not np.isnan(diff_results[i]['p_value']) and\n",
    "                  unit_root_results[i]['p_value'] > 0.05 and \n",
    "                  diff_results[i]['p_value'] < 0.05)\n",
    "\n",
    "print(f\"Variables I(1): {i1_count}/{len(df_vecm.columns)}\")\n",
    "if i1_count >= 2:\n",
    "    print(\"‚úÖ Condiciones cumplidas para VECM (‚â•2 variables I(1))\")\n",
    "else:\n",
    "    print(\"‚ùå Condiciones NO cumplidas para VECM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae492e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "üîç PASO 3B: TESTS ADICIONALES (ROBUSTEZ)\n",
      "==================================================\n",
      "\n",
      "üìä log_gdp_brazil:\n",
      "  Sin const   : stat=   3.306, p-val= 1.0000 -> I(1)\n",
      "  Con const   : stat=  -1.568, p-val= 0.4997 -> I(1)\n",
      "  Const+trend : stat=  -1.474, p-val= 0.8380 -> I(1)\n",
      "  KPSS (const)  : stat=   1.519, p-val= 0.0100 -> I(1)\n",
      "  KPSS (c+trend): stat=   0.372, p-val= 0.0100 -> I(1)\n",
      "--------------------------------------------------\n",
      "\n",
      "üìä log_tot_brazil:\n",
      "  Sin const   : stat=   0.225, p-val= 0.7541 -> I(1)\n",
      "  Con const   : stat=  -2.468, p-val= 0.1235 -> I(1)\n",
      "  Const+trend : stat=  -2.663, p-val= 0.2516 -> I(1)\n",
      "  KPSS (const)  : stat=   0.530, p-val= 0.0350 -> I(1)\n",
      "  KPSS (c+trend): stat=   0.133, p-val= 0.0734 -> I(0)\n",
      "--------------------------------------------------\n",
      "\n",
      "üìä log_ip_g7:\n",
      "  Sin const   : stat=   0.066, p-val= 0.7059 -> I(1)\n",
      "  Con const   : stat=  -4.897, p-val= 0.0000 -> I(0)\n",
      "  Const+trend : stat=  -5.070, p-val= 0.0002 -> I(0)\n",
      "  KPSS (const)  : stat=   0.288, p-val= 0.1000 -> I(0)\n",
      "  KPSS (c+trend): stat=   0.057, p-val= 0.1000 -> I(0)\n",
      "--------------------------------------------------\n",
      "\n",
      "üìä us_10y:\n",
      "  Sin const   : stat=  -1.251, p-val= 0.1939 -> I(1)\n",
      "  Con const   : stat=  -2.316, p-val= 0.1668 -> I(1)\n",
      "  Const+trend : stat=  -1.775, p-val= 0.7169 -> I(1)\n",
      "  KPSS (const)  : stat=   0.997, p-val= 0.0100 -> I(1)\n",
      "  KPSS (c+trend): stat=   0.238, p-val= 0.0100 -> I(1)\n",
      "--------------------------------------------------\n",
      "\n",
      "üìä risk_spread:\n",
      "  Sin const   : stat=  -1.539, p-val= 0.1162 -> I(1)\n",
      "  Con const   : stat=  -3.411, p-val= 0.0106 -> I(0)\n",
      "  Const+trend : stat=  -3.815, p-val= 0.0158 -> I(0)\n",
      "  KPSS (const)  : stat=   0.399, p-val= 0.0777 -> I(0)\n",
      "  KPSS (c+trend): stat=   0.057, p-val= 0.1000 -> I(0)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# PASO 3B: TESTS ADICIONALES DE RA√çZ UNITARIA\n",
    "print(\"=\"*50)\n",
    "print(\"üîç PASO 3B: TESTS ADICIONALES (ROBUSTEZ)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test ADF con diferentes especificaciones\n",
    "def test_adf_multiple(series, name):\n",
    "    \"\"\"Test ADF con diferentes especificaciones\"\"\"\n",
    "    specs = ['n', 'c', 'ct']  # none, constant, constant+trend\n",
    "    spec_names = ['Sin const', 'Con const', 'Const+trend']\n",
    "    \n",
    "    print(f\"\\nüìä {name}:\")\n",
    "    for i, spec in enumerate(specs):\n",
    "        try:\n",
    "            result = adfuller(series.dropna(), regression=spec)\n",
    "            stat, pval = result[0], result[1]\n",
    "            decision = \"I(0)\" if pval < 0.05 else \"I(1)\"\n",
    "            print(f\"  {spec_names[i]:<12}: stat={stat:>8.3f}, p-val={pval:>7.4f} -> {decision}\")\n",
    "        except:\n",
    "            print(f\"  {spec_names[i]:<12}: Error\")\n",
    "\n",
    "# Test KPSS (H0: Estacionaria - complementario al ADF)\n",
    "def test_kpss_robust(series, name):\n",
    "    \"\"\"Test KPSS robusto\"\"\"\n",
    "    if kpss is not None:\n",
    "        try:\n",
    "            # Con constante\n",
    "            kpss_c = kpss(series.dropna(), regression='c')\n",
    "            decision_c = \"I(0)\" if kpss_c[1] > 0.05 else \"I(1)\"\n",
    "            \n",
    "            # Con constante y tendencia  \n",
    "            kpss_ct = kpss(series.dropna(), regression='ct')\n",
    "            decision_ct = \"I(0)\" if kpss_ct[1] > 0.05 else \"I(1)\"\n",
    "            \n",
    "            print(f\"  KPSS (const)  : stat={kpss_c[0]:>8.3f}, p-val={kpss_c[1]:>7.4f} -> {decision_c}\")\n",
    "            print(f\"  KPSS (c+trend): stat={kpss_ct[0]:>8.3f}, p-val={kpss_ct[1]:>7.4f} -> {decision_ct}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  KPSS: Error - {e}\")\n",
    "\n",
    "# Ejecutar tests robustos\n",
    "for col in df_vecm.columns:\n",
    "    test_adf_multiple(df_vecm[col], col)\n",
    "    test_kpss_robust(df_vecm[col], col)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "014949e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "üîç PASO 4: COINTEGRACI√ìN\n",
      "==================================================\n",
      "‚úÖ Variables del modelo completo: ['log_gdp_brazil', 'log_ip_g7', 'log_tot_brazil', 'us_10y', 'risk_spread']\n",
      "üìä Observaciones: 99\n",
      "\n",
      "üìä TEST JOHANSEN (5 variables):\n",
      "Estad√≠stico traza: [89.18124676 54.76260563 25.77998298 11.37797131  1.21738178]\n",
      "Valores cr√≠ticos 5%: [79.3422 55.2459 35.0116 18.3985  3.8415]\n",
      "‚úÖ Relaciones de cointegraci√≥n: 1\n",
      "\n",
      "üéØ Usar modelo de 5 variables (siguiendo Talvi)\n"
     ]
    }
   ],
   "source": [
    "# PASO 4: PREPARACI√ìN PARA VECM Y TEST DE COINTEGRACI√ìN\n",
    "print(\"=\"*50)\n",
    "print(\"üîç PASO 4: COINTEGRACI√ìN\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "\n",
    "\n",
    "# Usar todas las 5 variables del modelo original\n",
    "vecm_vars_full = ['log_gdp_brazil', 'log_ip_g7', 'log_tot_brazil', 'us_10y', 'risk_spread']\n",
    "df_vecm_full = df_vecm[vecm_vars_full].copy()\n",
    "\n",
    "print(f\"‚úÖ Variables del modelo completo: {vecm_vars_full}\")\n",
    "print(f\"üìä Observaciones: {len(df_vecm_full)}\")\n",
    "\n",
    "# Test de cointegraci√≥n con 5 variables\n",
    "if coint_johansen is not None:\n",
    "    johansen_result = coint_johansen(df_vecm_full.values, det_order=1, k_ar_diff=2)\n",
    "    print(f\"\\nüìä TEST JOHANSEN (5 variables):\")\n",
    "    print(f\"Estad√≠stico traza: {johansen_result.lr1}\")\n",
    "    print(f\"Valores cr√≠ticos 5%: {johansen_result.cvt[:, 1]}\")\n",
    "    n_coint = sum(johansen_result.lr1 > johansen_result.cvt[:, 1])\n",
    "    print(f\"‚úÖ Relaciones de cointegraci√≥n: {n_coint}\")\n",
    "\n",
    "print(f\"\\nüéØ Usar modelo de 5 variables (siguiendo Talvi)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1e52ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "üîç PASO 5: ESTIMACI√ìN VECM CON DUMMY EX√ìGENA\n",
      "==================================================\n",
      "==================================================\n",
      "üîß PREPARANDO Y ALINEANDO DATOS\n",
      "==================================================\n",
      "‚úÖ √çndice de df_endog (trimestral) convertido a Datetime.\n",
      "‚úÖ √çndice de df_exog (mensual) convertido a Datetime.\n",
      "‚úÖ √çndice de df_dummy (mensual) convertido a Datetime.\n",
      "‚úÖ Datos mensuales agregados a trimestres.\n",
      "‚úÖ √çndices de ambos DataFrames estandarizados al inicio del trimestre.\n",
      "üìä Datos alineados listos con 99 observaciones.\n",
      "üìÖ Nuevo per√≠odo: 2000-04-01 a 2024-10-01\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.api import VECM\n",
    "\n",
    "# PASO 5: ESTIMACI√ìN DEL MODELO VECM CON VARIABLE EX√ìGENA\n",
    "print(\"=\"*50)\n",
    "print(\"üîç PASO 5: ESTIMACI√ìN VECM CON DUMMY EX√ìGENA\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. Separar las variables end√≥genas de la ex√≥gena\n",
    "# Las end√≥genas son las que se explican mutuamente en el sistema\n",
    "endog_vars = ['log_gdp_brazil']\n",
    "exog_vars = ['log_ip_g7', 'log_tot_brazil', 'us_10y', 'risk_spread']\n",
    "df_endog = df_vecm_full[endog_vars]\n",
    "df_exog = df_vecm_full[exog_vars]\n",
    "\n",
    "# La ex√≥gena es la dummy. Usamos doble corchete para que sea un DataFrame.\n",
    "df_dummy = df_combined[['pandemia_dummy']]\n",
    "\n",
    "\n",
    "# --- PASO 4.5: PREPARACI√ìN DE DATOS (VERSI√ìN FINAL) ---\n",
    "print(\"=\"*50)\n",
    "print(\"üîß PREPARANDO Y ALINEANDO DATOS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. Preparar df_endog (Datos Trimestrales)\n",
    "# Asumiendo que las fechas (ej. 200004) est√°n en el √≠ndice.\n",
    "# Lo convertimos a string y luego a fecha con el formato correcto.\n",
    "df_endog.index = pd.to_datetime(df_endog.index.astype(str), format='%Y%m')\n",
    "print(\"‚úÖ √çndice de df_endog (trimestral) convertido a Datetime.\")\n",
    "\n",
    "# 2. Preparar df_exog (Datos Mensuales)\n",
    "# Hacemos exactamente lo mismo: asumimos que las fechas (ej. 200001) est√°n en el √≠ndice.\n",
    "df_exog.index = pd.to_datetime(df_exog.index.astype(str), format='%Y%m')\n",
    "print(\"‚úÖ √çndice de df_exog (mensual) convertido a Datetime.\")\n",
    "\n",
    "df_dummy.index = pd.to_datetime(df_dummy.index.astype(str), format='%Y%m')\n",
    "print(\"‚úÖ √çndice de df_dummy (mensual) convertido a Datetime.\")\n",
    "\n",
    "# 3. Convertir df_exog de Mensual a Trimestral\n",
    "df_exog_quarterly = df_exog.resample('Q').max()\n",
    "df_dummy_quarterly = df_dummy.resample('Q').max()\n",
    "print(\"‚úÖ Datos mensuales agregados a trimestres.\")\n",
    "\n",
    "# 4. Estandarizar √çndices (Paso Clave para la Uni√≥n)\n",
    "# Forzamos que ambos usen el primer d√≠a del trimestre como referencia.\n",
    "df_endog.index = df_endog.index.to_period('Q').start_time\n",
    "df_exog_quarterly.index = df_exog_quarterly.index.to_period('Q').start_time\n",
    "df_dummy_quarterly.index = df_dummy_quarterly.index.to_period('Q').start_time\n",
    "print(\"‚úÖ √çndices de ambos DataFrames estandarizados al inicio del trimestre.\")\n",
    "\n",
    "# 5. Unir los DataFrames y Limpiar\n",
    "df_aligned = df_endog.join(df_exog_quarterly, how='inner')\n",
    "df_aligned = df_aligned.join(df_dummy_quarterly, how='inner')\n",
    "df_aligned.dropna(inplace=True)\n",
    "print(f\"üìä Datos alineados listos con {len(df_aligned)} observaciones.\")\n",
    "\n",
    "if not df_aligned.empty:\n",
    "    print(f\"üìÖ Nuevo per√≠odo: {df_aligned.index.min().strftime('%Y-%m-%d')} a {df_aligned.index.max().strftime('%Y-%m-%d')}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è ADVERTENCIA: El DataFrame sigue vac√≠o. Revisa que los rangos de fechas se solapen.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df9090f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üéØ IMPLEMENTANDO METODOLOG√çA BID - MODELO DE CORRECCI√ìN DE ERROR\n",
      "============================================================\n",
      "\n",
      "üìä PASO 1: ESTIMANDO RELACI√ìN DE LARGO PLAZO\n",
      "----------------------------------------\n",
      "‚úÖ Relaci√≥n de largo plazo estimada:\n",
      "   R¬≤ = 0.7066\n",
      "   const: -27.8131 (p-valor: 0.0000)\n",
      "   log_ip_g7: 0.6358 (p-valor: 0.0070)\n",
      "   log_tot_brazil: 8.1661 (p-valor: 0.0000)\n",
      "   us_10y: -0.0650 (p-valor: 0.0000)\n",
      "   risk_spread: -0.0081 (p-valor: 0.0596)\n",
      "\n",
      "üîß PASO 2: CALCULANDO T√âRMINO DE CORRECCI√ìN DE ERROR\n",
      "----------------------------------------\n",
      "   Media del ECT: -0.000000 (debe estar cerca de 0)\n",
      "   Desv. Est√°ndar ECT: 0.0873\n",
      "   Test de Cointegraci√≥n (Engle-Granger): 0.9927\n",
      "   ‚ö†Ô∏è Cointegraci√≥n d√©bil (p ‚â• 0.05)\n",
      "\n",
      "üìà PASO 3: ESTIMANDO MODELO DE CORRECCI√ìN DE ERROR\n",
      "----------------------------------------\n",
      "‚úÖ Modelo de Correcci√≥n de Error estimado:\n",
      "   R¬≤ = 0.5949\n",
      "   Observaciones: 98.0\n",
      "\n",
      "üîß COEFICIENTES DEL MODELO:\n",
      "   Œ± (Correcci√≥n de Error): -0.0184 \n",
      "      ‚úÖ Coeficiente negativo - Sistema estable\n",
      "      üìà Velocidad de ajuste: 1.8% por trimestre\n",
      "   Œ≥ (D_log_ip_g7): 0.2830 ***\n",
      "   Œ≥ (D_log_tot_brazil): -0.0901 \n",
      "   Œ≥ (D_us_10y): -0.0027 \n",
      "   Œ≥ (D_risk_spread): -0.0026 **\n",
      "   Œ¥ (Efecto Pandemia): -0.0058 \n",
      "\n",
      "üìä INTERPRETACI√ìN:\n",
      "   - El modelo explica 59.5% de la variaci√≥n en el crecimiento del PIB\n",
      "   - Efectos de largo plazo capturados en el t√©rmino de correcci√≥n de error\n",
      "   - Efectos de corto plazo capturados en las variables en diferencias\n",
      "\n",
      "‚úÖ Modelo BID implementado exitosamente - Resultados guardados en 'resultados_bid'\n"
     ]
    }
   ],
   "source": [
    "# SOLUCI√ìN AL ERROR: \"Only gave one variable to VECM\"\n",
    "# Dos opciones para implementar la metodolog√≠a del BID\n",
    "\n",
    "# =============================================================================\n",
    "# OPCI√ìN 1: MODELO DE CORRECCI√ìN DE ERROR MANUAL (RECOMENDADO)\n",
    "# Implementa exactamente lo que hace el BID\n",
    "# =============================================================================\n",
    "\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üéØ IMPLEMENTANDO METODOLOG√çA BID - MODELO DE CORRECCI√ìN DE ERROR\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Paso 1: Estimar relaci√≥n de cointegraci√≥n (largo plazo)\n",
    "print(\"\\nüìä PASO 1: ESTIMANDO RELACI√ìN DE LARGO PLAZO\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "# Variables para la relaci√≥n de largo plazo (sin la dummy)\n",
    "long_run_vars = ['log_ip_g7', 'log_tot_brazil', 'us_10y', 'risk_spread']\n",
    "X_longrun = df_aligned[long_run_vars]\n",
    "y_longrun = df_aligned['log_gdp_brazil']\n",
    "\n",
    "# Agregar constante para la regresi√≥n de largo plazo\n",
    "X_longrun_const = pd.concat([pd.Series(1, index=X_longrun.index, name='const'), X_longrun], axis=1)\n",
    "\n",
    "# Estimar relaci√≥n de largo plazo: PIB = Œ≤‚ÇÄ + Œ≤‚ÇÅ*IP_G7 + Œ≤‚ÇÇ*TOT + Œ≤‚ÇÉ*US10Y + Œ≤‚ÇÑ*RISK + error\n",
    "modelo_largo_plazo = OLS(y_longrun, X_longrun_const).fit()\n",
    "\n",
    "print(f\"‚úÖ Relaci√≥n de largo plazo estimada:\")\n",
    "print(f\"   R¬≤ = {modelo_largo_plazo.rsquared:.4f}\")\n",
    "for i, (var, coef) in enumerate(zip(X_longrun_const.columns, modelo_largo_plazo.params)):\n",
    "    print(f\"   {var}: {coef:.4f} (p-valor: {modelo_largo_plazo.pvalues.iloc[i]:.4f})\")\n",
    "\n",
    "# Paso 2: Calcular t√©rmino de correcci√≥n de error\n",
    "print(f\"\\nüîß PASO 2: CALCULANDO T√âRMINO DE CORRECCI√ìN DE ERROR\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "# T√©rmino de correcci√≥n de error = PIB_actual - PIB_equilibrio\n",
    "# ECT_t = PIB_t - (Œ≤‚ÇÄ + Œ≤‚ÇÅ*IP_G7_t + Œ≤‚ÇÇ*TOT_t + Œ≤‚ÇÉ*US10Y_t + Œ≤‚ÇÑ*RISK_t)\n",
    "pib_equilibrio = modelo_largo_plazo.predict(X_longrun_const)\n",
    "ect = y_longrun - pib_equilibrio\n",
    "ect.name = 'ECT'\n",
    "\n",
    "print(f\"   Media del ECT: {ect.mean():.6f} (debe estar cerca de 0)\")\n",
    "print(f\"   Desv. Est√°ndar ECT: {ect.std():.4f}\")\n",
    "\n",
    "# Test de cointegraci√≥n\n",
    "coint_test = coint(y_longrun, X_longrun)\n",
    "print(f\"   Test de Cointegraci√≥n (Engle-Granger): {coint_test[1]:.4f}\")\n",
    "if coint_test[1] < 0.05:\n",
    "    print(\"   ‚úÖ Evidencia de cointegraci√≥n (p < 0.05)\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Cointegraci√≥n d√©bil (p ‚â• 0.05)\")\n",
    "\n",
    "# Paso 3: Estimar modelo de correcci√≥n de error (corto plazo)\n",
    "print(f\"\\nüìà PASO 3: ESTIMANDO MODELO DE CORRECCI√ìN DE ERROR\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "# Preparar variables en diferencias\n",
    "df_diff = df_aligned.diff().dropna()\n",
    "df_diff.columns = [f'D_{col}' for col in df_diff.columns]\n",
    "\n",
    "# El modelo de correcci√≥n de error:\n",
    "# Œî(PIB_t) = Œ± √ó ECT_{t-1} + Œ≥‚ÇÅ√óŒî(IP_G7_t) + Œ≥‚ÇÇ√óŒî(TOT_t) + Œ≥‚ÇÉ√óŒî(US10Y_t) + Œ≥‚ÇÑ√óŒî(RISK_t) + Œ¥√óPANDEMIA_t + Œµ_t\n",
    "\n",
    "# Preparar datos para ECM\n",
    "# ECT rezagado 1 per√≠odo\n",
    "ect_lagged = ect.shift(1)\n",
    "ect_lagged.name = 'ECT_lag1'\n",
    "\n",
    "# Variables explicativas del modelo de corto plazo\n",
    "short_run_vars = ['D_log_ip_g7', 'D_log_tot_brazil', 'D_us_10y', 'D_risk_spread']\n",
    "X_shortrun = df_diff[short_run_vars]\n",
    "\n",
    "# Agregar ECT rezagado y dummy de pandemia\n",
    "X_ecm = pd.concat([\n",
    "    ect_lagged,\n",
    "    X_shortrun,\n",
    "    df_aligned['pandemia_dummy']\n",
    "], axis=1).dropna()\n",
    "\n",
    "# Variable dependiente: cambio en PIB\n",
    "y_ecm = df_diff['D_log_gdp_brazil'].loc[X_ecm.index]\n",
    "\n",
    "# Estimar modelo de correcci√≥n de error\n",
    "modelo_ecm = OLS(y_ecm, X_ecm).fit()\n",
    "\n",
    "print(f\"‚úÖ Modelo de Correcci√≥n de Error estimado:\")\n",
    "print(f\"   R¬≤ = {modelo_ecm.rsquared:.4f}\")\n",
    "print(f\"   Observaciones: {modelo_ecm.nobs}\")\n",
    "\n",
    "print(f\"\\nüîß COEFICIENTES DEL MODELO:\")\n",
    "for var, coef, pval in zip(X_ecm.columns, modelo_ecm.params, modelo_ecm.pvalues):\n",
    "    significance = \"***\" if pval < 0.01 else \"**\" if pval < 0.05 else \"*\" if pval < 0.10 else \"\"\n",
    "    if var == 'ECT_lag1':\n",
    "        print(f\"   Œ± (Correcci√≥n de Error): {coef:.4f} {significance}\")\n",
    "        if coef < 0:\n",
    "            print(f\"      ‚úÖ Coeficiente negativo - Sistema estable\")\n",
    "            print(f\"      üìà Velocidad de ajuste: {abs(coef)*100:.1f}% por trimestre\")\n",
    "        else:\n",
    "            print(f\"      ‚ö†Ô∏è Coeficiente positivo - Revisar especificaci√≥n\")\n",
    "    elif var == 'pandemia_dummy':\n",
    "        print(f\"   Œ¥ (Efecto Pandemia): {coef:.4f} {significance}\")\n",
    "    else:\n",
    "        print(f\"   Œ≥ ({var}): {coef:.4f} {significance}\")\n",
    "\n",
    "print(f\"\\nüìä INTERPRETACI√ìN:\")\n",
    "print(f\"   - El modelo explica {modelo_ecm.rsquared*100:.1f}% de la variaci√≥n en el crecimiento del PIB\")\n",
    "print(f\"   - Efectos de largo plazo capturados en el t√©rmino de correcci√≥n de error\")\n",
    "print(f\"   - Efectos de corto plazo capturados en las variables en diferencias\")\n",
    "\n",
    "# Guardar resultados\n",
    "resultados_bid = {\n",
    "    'modelo_largo_plazo': modelo_largo_plazo,\n",
    "    'modelo_ecm': modelo_ecm,\n",
    "    'ect': ect,\n",
    "    'r2_largo_plazo': modelo_largo_plazo.rsquared,\n",
    "    'r2_corto_plazo': modelo_ecm.rsquared,\n",
    "    'alpha': modelo_ecm.params['ECT_lag1'],\n",
    "    'cointegration_pvalue': coint_test[1]\n",
    "}\n",
    "\n",
    "print(f\"\\n‚úÖ Modelo BID implementado exitosamente - Resultados guardados en 'resultados_bid'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fef62f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üîß DIAGN√ìSTICOS Y MEJORAS DEL MODELO BID\n",
      "============================================================\n",
      "\n",
      "üìä 1. TESTS DE RA√çZ UNITARIA (VERIFICAR I(1))\n",
      "--------------------------------------------------\n",
      "log_gdp_brazil:\n",
      "  Niveles: ADF=-1.568, p-valor=0.500 (No estacionaria)\n",
      "  Diferencias: ADF=-7.723, p-valor=0.000 (Estacionaria)\n",
      "log_ip_g7:\n",
      "  Niveles: ADF=-4.897, p-valor=0.000 (Estacionaria)\n",
      "  Diferencias: ADF=-13.591, p-valor=0.000 (Estacionaria)\n",
      "log_tot_brazil:\n",
      "  Niveles: ADF=-2.468, p-valor=0.124 (No estacionaria)\n",
      "  Diferencias: ADF=-11.339, p-valor=0.000 (Estacionaria)\n",
      "us_10y:\n",
      "  Niveles: ADF=-2.316, p-valor=0.167 (No estacionaria)\n",
      "  Diferencias: ADF=-9.914, p-valor=0.000 (Estacionaria)\n",
      "risk_spread:\n",
      "  Niveles: ADF=-3.411, p-valor=0.011 (Estacionaria)\n",
      "  Diferencias: ADF=-7.952, p-valor=0.000 (Estacionaria)\n",
      "\n",
      "‚úÖ Variables que son I(1): ['log_gdp_brazil', 'log_tot_brazil', 'us_10y']\n",
      "‚ÑπÔ∏è Para cointegraci√≥n, todas las variables deben ser I(1)\n",
      "\n",
      "üîó 2. TEST DE JOHANSEN PARA COINTEGRACI√ìN\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'coint_johansen' from 'statsmodels.tsa.stattools' (c:\\Users\\Usuario\\anaconda3\\envs\\tftimeseriesII\\lib\\site-packages\\statsmodels\\tsa\\stattools.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10380\\1416345157.py\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstattools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcoint_johansen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;31m# Preparar datos para Johansen (solo variables I(1))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'coint_johansen' from 'statsmodels.tsa.stattools' (c:\\Users\\Usuario\\anaconda3\\envs\\tftimeseriesII\\lib\\site-packages\\statsmodels\\tsa\\stattools.py)"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MEJORAS Y DIAGN√ìSTICOS PARA EL MODELO BID\n",
    "# =============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.stats.diagnostic import het_white, acorr_breusch_godfrey\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üîß DIAGN√ìSTICOS Y MEJORAS DEL MODELO BID\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# --- 1. VERIFICAR ESTACIONARIEDAD DE LAS SERIES ---\n",
    "print(\"\\nüìä 1. TESTS DE RA√çZ UNITARIA (VERIFICAR I(1))\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "def test_estacionariedad(serie, nombre):\n",
    "    # Test ADF en niveles\n",
    "    adf_niveles = adfuller(serie.dropna(), autolag='AIC')\n",
    "    # Test ADF en diferencias\n",
    "    adf_diff = adfuller(serie.diff().dropna(), autolag='AIC')\n",
    "    \n",
    "    print(f\"{nombre}:\")\n",
    "    print(f\"  Niveles: ADF={adf_niveles[0]:.3f}, p-valor={adf_niveles[1]:.3f} \" + \n",
    "          (\"(Estacionaria)\" if adf_niveles[1] < 0.05 else \"(No estacionaria)\"))\n",
    "    print(f\"  Diferencias: ADF={adf_diff[0]:.3f}, p-valor={adf_diff[1]:.3f} \" + \n",
    "          (\"(Estacionaria)\" if adf_diff[1] < 0.05 else \"(No estacionaria)\"))\n",
    "    \n",
    "    return adf_niveles[1] > 0.05 and adf_diff[1] < 0.05  # Es I(1)?\n",
    "\n",
    "variables_test = ['log_gdp_brazil', 'log_ip_g7', 'log_tot_brazil', 'us_10y', 'risk_spread']\n",
    "i1_variables = []\n",
    "\n",
    "for var in variables_test:\n",
    "    if var in df_aligned.columns:\n",
    "        es_i1 = test_estacionariedad(df_aligned[var], var)\n",
    "        if es_i1:\n",
    "            i1_variables.append(var)\n",
    "\n",
    "print(f\"\\n‚úÖ Variables que son I(1): {i1_variables}\")\n",
    "print(f\"‚ÑπÔ∏è Para cointegraci√≥n, todas las variables deben ser I(1)\")\n",
    "\n",
    "# --- 2. TEST DE JOHANSEN (M√ÅS ROBUSTO) ---\n",
    "print(f\"\\nüîó 2. TEST DE JOHANSEN PARA COINTEGRACI√ìN\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "from statsmodels.tsa.stattools import coint_johansen\n",
    "\n",
    "# Preparar datos para Johansen (solo variables I(1))\n",
    "if len(i1_variables) >= 2:\n",
    "    datos_johansen = df_aligned[i1_variables].dropna()\n",
    "    \n",
    "    # Test de Johansen\n",
    "    resultado_johansen = coint_johansen(datos_johansen.values, det_order=1, k_ar_diff=1)\n",
    "    \n",
    "    print(f\"Variables incluidas: {i1_variables}\")\n",
    "    print(f\"Observaciones: {len(datos_johansen)}\")\n",
    "    \n",
    "    # Resultados del test de traza\n",
    "    for i in range(len(i1_variables)):\n",
    "        estadistico = resultado_johansen.lr1[i]\n",
    "        valor_critico_5 = resultado_johansen.cvt[i, 1]\n",
    "        print(f\"H0: r‚â§{i} vs H1: r>{i}\")\n",
    "        print(f\"  Estad√≠stico: {estadistico:.3f}, Valor cr√≠tico 5%: {valor_critico_5:.3f}\")\n",
    "        if estadistico > valor_critico_5:\n",
    "            print(f\"  ‚úÖ Rechaza H0 - Hay al menos {i+1} relaci√≥n(es) de cointegraci√≥n\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå No rechaza H0 - M√°ximo {i} relaci√≥n(es)\")\n",
    "            break\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No hay suficientes variables I(1) para test de Johansen\")\n",
    "\n",
    "# --- 3. DIAGN√ìSTICOS DE RESIDUOS ---\n",
    "print(f\"\\nüîç 3. DIAGN√ìSTICOS DE RESIDUOS DEL ECM\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "residuos_ecm = modelo_ecm.resid\n",
    "\n",
    "# Test de normalidad\n",
    "from scipy.stats import jarque_bera\n",
    "jb_stat, jb_pvalue = jarque_bera(residuos_ecm)\n",
    "print(f\"Test Jarque-Bera (Normalidad): {jb_stat:.3f}, p-valor: {jb_pvalue:.3f}\")\n",
    "\n",
    "# Test de autocorrelaci√≥n\n",
    "try:\n",
    "    bg_test = acorr_breusch_godfrey(modelo_ecm, nlags=4)\n",
    "    print(f\"Test Breusch-Godfrey (Autocorr): {bg_test[0]:.3f}, p-valor: {bg_test[1]:.3f}\")\n",
    "except:\n",
    "    print(\"Test de autocorrelaci√≥n no disponible\")\n",
    "\n",
    "# Test de heterocedasticidad\n",
    "try:\n",
    "    white_test = het_white(residuos_ecm, modelo_ecm.model.exog)\n",
    "    print(f\"Test White (Heteroced): {white_test[0]:.3f}, p-valor: {white_test[1]:.3f}\")\n",
    "except:\n",
    "    print(\"Test de heterocedasticidad no disponible\")\n",
    "\n",
    "# --- 4. GR√ÅFICOS DE DIAGN√ìSTICO ---\n",
    "print(f\"\\nüìà 4. GR√ÅFICOS DE DIAGN√ìSTICO\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "fig.suptitle('Diagn√≥sticos del Modelo de Correcci√≥n de Error', fontsize=14)\n",
    "\n",
    "# Residuos vs tiempo\n",
    "axes[0,0].plot(residuos_ecm.index, residuos_ecm.values)\n",
    "axes[0,0].axhline(y=0, color='r', linestyle='--')\n",
    "axes[0,0].set_title('Residuos vs Tiempo')\n",
    "axes[0,0].set_ylabel('Residuos')\n",
    "\n",
    "# Q-Q plot\n",
    "from scipy.stats import probplot\n",
    "probplot(residuos_ecm, dist=\"norm\", plot=axes[0,1])\n",
    "axes[0,1].set_title('Q-Q Plot (Normalidad)')\n",
    "\n",
    "# Histograma de residuos\n",
    "axes[1,0].hist(residuos_ecm, bins=15, alpha=0.7, density=True)\n",
    "axes[1,0].set_title('Histograma de Residuos')\n",
    "axes[1,0].set_xlabel('Residuos')\n",
    "\n",
    "# Residuos vs valores ajustados\n",
    "valores_ajustados = modelo_ecm.fittedvalues\n",
    "axes[1,1].scatter(valores_ajustados, residuos_ecm, alpha=0.6)\n",
    "axes[1,1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[1,1].set_title('Residuos vs Valores Ajustados')\n",
    "axes[1,1].set_xlabel('Valores Ajustados')\n",
    "axes[1,1].set_ylabel('Residuos')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- 5. AN√ÅLISIS DEL T√âRMINO DE CORRECCI√ìN DE ERROR ---\n",
    "print(f\"\\n‚öñÔ∏è 5. AN√ÅLISIS DEL T√âRMINO DE CORRECCI√ìN DE ERROR\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Gr√°fico del ECT\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(ect.index, ect.values, linewidth=1.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--', alpha=0.7)\n",
    "plt.title('T√©rmino de Correcci√≥n de Error (ECT)')\n",
    "plt.ylabel('Desviaci√≥n del Equilibrio')\n",
    "plt.xlabel('Tiempo')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Estad√≠sticas del ECT\n",
    "print(f\"Estad√≠sticas del ECT:\")\n",
    "print(f\"  Media: {ect.mean():.6f}\")\n",
    "print(f\"  Mediana: {ect.median():.4f}\")\n",
    "print(f\"  Desv. Est√°ndar: {ect.std():.4f}\")\n",
    "print(f\"  M√≠n: {ect.min():.4f}, M√°x: {ect.max():.4f}\")\n",
    "\n",
    "# --- 6. RECOMENDACIONES ---\n",
    "print(f\"\\nüí° 6. RECOMENDACIONES PARA MEJORAR EL MODELO\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Basado en los diagn√≥sticos:\")\n",
    "print(\"1. ‚úÖ El modelo tiene buen ajuste (R¬≤ = 59.5%)\")\n",
    "print(\"2. ‚úÖ Coeficiente de correcci√≥n de error negativo (sistema estable)\")\n",
    "print(\"3. ‚ö†Ô∏è Ajuste lento (1.8% por trimestre) - normal en econom√≠as emergentes\")\n",
    "\n",
    "if jb_pvalue < 0.05:\n",
    "    print(\"4. ‚ö†Ô∏è Residuos no normales - considerar outliers o cambio estructural\")\n",
    "else:\n",
    "    print(\"4. ‚úÖ Residuos aproximadamente normales\")\n",
    "\n",
    "print(\"\\nSugerencias:\")\n",
    "print(\"‚Ä¢ Considerar breaks estructurales en el per√≠odo de an√°lisis\")\n",
    "print(\"‚Ä¢ Incluir m√°s variables de control (t√©rminos cuadr√°ticos, interacciones)\")\n",
    "print(\"‚Ä¢ Verificar robustez con diferentes especificaciones del modelo\")\n",
    "print(\"‚Ä¢ Analizar funciones impulso-respuesta para interpretaci√≥n econ√≥mica\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c2ac008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üîß MODELO BID CORREGIDO - INTEGRACI√ìN MIXTA\n",
      "============================================================\n",
      "\n",
      "üìã ESPECIFICACI√ìN DEL MODELO CORREGIDA:\n",
      "----------------------------------------\n",
      "Variables I(1): ['log_gdp_brazil', 'log_tot_brazil', 'us_10y']\n",
      "Variables I(0): ['log_ip_g7', 'risk_spread']\n",
      "\n",
      "üîó PASO 1: COINTEGRACI√ìN SOLO ENTRE VARIABLES I(1)\n",
      "--------------------------------------------------\n",
      "Relaci√≥n de Cointegraci√≥n (solo I(1)):\n",
      "  R¬≤ = 0.6278\n",
      "  const: -28.4920 *** (p=0.0000)\n",
      "  log_tot_brazil: 8.9371 *** (p=0.0000)\n",
      "  us_10y: -0.0652 *** (p=0.0000)\n",
      "\n",
      "Test Engle-Granger: p-valor = 0.6900\n",
      "  ‚ö†Ô∏è Cointegraci√≥n d√©bil entre variables I(1)\n",
      "\n",
      "üìä PASO 2: MODELO DE CORRECCI√ìN DE ERROR AMPLIADO\n",
      "--------------------------------------------------\n",
      "Observaciones para ECM ampliado: 98\n",
      "Variables explicativas: ['ECT_lag1', 'D_log_tot_brazil', 'D_us_10y', 'log_ip_g7', 'risk_spread', 'pandemia_dummy']\n",
      "\n",
      "üéØ PASO 3: ESTIMACI√ìN DEL ECM AMPLIADO\n",
      "--------------------------------------------------\n",
      "‚úÖ Modelo de Correcci√≥n de Error Ampliado:\n",
      "   R¬≤ = 0.3349\n",
      "   R¬≤ Ajustado = 0.2915\n",
      "   Observaciones: 98.0\n",
      "   F-statistic: 7.72 (p=0.0000)\n",
      "\n",
      "üîß COEFICIENTES DEL MODELO AMPLIADO:\n",
      "   Œ± (Correcci√≥n Error I(1)): -0.0337 ** (se=0.0169)\n",
      "      ‚úÖ Negativo - Ajuste hacia equilibrio de largo plazo\n",
      "      üìà Velocidad: 3.4% por trimestre\n",
      "   Œ≥ (D_log_tot_brazil): 1.5789 *** (se=0.3998) [Efecto corto plazo]\n",
      "   Œ≥ (D_us_10y): 0.0029  (se=0.0038) [Efecto corto plazo]\n",
      "   Œ≤ (log_ip_g7): 0.0028 *** (se=0.0008) [Variable I(0)]\n",
      "   Œ≤ (risk_spread): -0.0012 * (se=0.0006) [Variable I(0)]\n",
      "   Œ¥ (Pandemia): -0.0164 * (se=0.0087)\n",
      "\n",
      "üìä PASO 4: COMPARACI√ìN DE ESPECIFICACIONES\n",
      "--------------------------------------------------\n",
      "MODELO ORIGINAL (todas las variables):\n",
      "  R¬≤ = 0.5949\n",
      "  Œ± (correcci√≥n error) = -0.0184\n",
      "\n",
      "MODELO CORREGIDO (separando I(1)/I(0)):\n",
      "  R¬≤ = 0.3349\n",
      "  Œ± (correcci√≥n error) = -0.0337\n",
      "\n",
      "üìà Mejora en R¬≤: -0.2600\n",
      "‚ö†Ô∏è El modelo original ten√≠a mejor ajuste\n",
      "\n",
      "üí° PASO 5: INTERPRETACI√ìN ECON√ìMICA CORREGIDA\n",
      "--------------------------------------------------\n",
      "EFECTOS DE LARGO PLAZO (v√≠a cointegraci√≥n I(1)):\n",
      "  ‚úÖ PIB se ajusta 3.4% por trimestre hacia equilibrio\n",
      "  üìÖ Semivida del shock: ~20.2 trimestres\n",
      "\n",
      "EFECTOS DE CORTO PLAZO:\n",
      "  D_log_tot_brazil: 1.5789 (impacto inmediato)\n",
      "  D_us_10y: 0.0029 (impacto inmediato)\n",
      "\n",
      "EFECTOS CONTEMPOR√ÅNEOS (variables I(0)):\n",
      "  log_ip_g7: 0.0028 (efecto en niveles)\n",
      "  risk_spread: -0.0012 (efecto en niveles)\n",
      "\n",
      "‚úÖ Modelo BID corregido completado - Resultados en 'resultados_bid_corregido'\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MODELO BID CORREGIDO PARA INTEGRACI√ìN MIXTA I(1)/I(0)\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üîß MODELO BID CORREGIDO - INTEGRACI√ìN MIXTA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Basado en los tests de ra√≠z unitaria:\n",
    "# I(1): log_gdp_brazil, log_tot_brazil, us_10y\n",
    "# I(0): log_ip_g7, risk_spread\n",
    "\n",
    "# --- ESPECIFICACI√ìN CORREGIDA ---\n",
    "print(\"\\nüìã ESPECIFICACI√ìN DEL MODELO CORREGIDA:\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "# Variables I(1) - pueden tener relaci√≥n de cointegraci√≥n\n",
    "variables_i1 = ['log_gdp_brazil', 'log_tot_brazil', 'us_10y']\n",
    "print(f\"Variables I(1): {variables_i1}\")\n",
    "\n",
    "# Variables I(0) - entran en niveles como regresores adicionales\n",
    "variables_i0 = ['log_ip_g7', 'risk_spread']  \n",
    "print(f\"Variables I(0): {variables_i0}\")\n",
    "\n",
    "# --- PASO 1: RELACI√ìN DE LARGO PLAZO SOLO CON VARIABLES I(1) ---\n",
    "print(f\"\\nüîó PASO 1: COINTEGRACI√ìN SOLO ENTRE VARIABLES I(1)\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "# Relaci√≥n de largo plazo: PIB_Brasil ~ TOT_Brasil + US_10Y\n",
    "X_coint = df_aligned[['log_tot_brazil', 'us_10y']]\n",
    "y_coint = df_aligned['log_gdp_brazil']\n",
    "\n",
    "# Agregar constante\n",
    "X_coint_const = pd.concat([pd.Series(1, index=X_coint.index, name='const'), X_coint], axis=1)\n",
    "\n",
    "# Estimar relaci√≥n de cointegraci√≥n\n",
    "modelo_coint = OLS(y_coint, X_coint_const).fit()\n",
    "print(f\"Relaci√≥n de Cointegraci√≥n (solo I(1)):\")\n",
    "print(f\"  R¬≤ = {modelo_coint.rsquared:.4f}\")\n",
    "\n",
    "for var, coef, pval in zip(X_coint_const.columns, modelo_coint.params, modelo_coint.pvalues):\n",
    "    sig = \"***\" if pval < 0.01 else \"**\" if pval < 0.05 else \"*\" if pval < 0.10 else \"\"\n",
    "    print(f\"  {var}: {coef:.4f} {sig} (p={pval:.4f})\")\n",
    "\n",
    "# Test de cointegraci√≥n Engle-Granger\n",
    "coint_test = coint(y_coint, X_coint)\n",
    "print(f\"\\nTest Engle-Granger: p-valor = {coint_test[1]:.4f}\")\n",
    "if coint_test[1] < 0.05:\n",
    "    print(\"  ‚úÖ Evidencia de cointegraci√≥n entre variables I(1)\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è Cointegraci√≥n d√©bil entre variables I(1)\")\n",
    "\n",
    "# Calcular ECT de la relaci√≥n de cointegraci√≥n\n",
    "pib_equilibrio_coint = modelo_coint.predict(X_coint_const)\n",
    "ect_coint = y_coint - pib_equilibrio_coint\n",
    "ect_coint.name = 'ECT_I1'\n",
    "\n",
    "# --- PASO 2: MODELO DE CORRECCI√ìN DE ERROR AMPLIADO ---\n",
    "print(f\"\\nüìä PASO 2: MODELO DE CORRECCI√ìN DE ERROR AMPLIADO\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Preparar variables\n",
    "df_diff = df_aligned.diff().dropna()\n",
    "\n",
    "# ECT rezagado (de la relaci√≥n de cointegraci√≥n I(1))\n",
    "ect_lag1 = ect_coint.shift(1)\n",
    "ect_lag1.name = 'ECT_lag1'\n",
    "\n",
    "# Variables en diferencias (efectos de corto plazo de variables I(1))\n",
    "diff_vars_i1 = ['log_tot_brazil', 'us_10y']  # Excluir PIB (variable dependiente)\n",
    "X_diff_i1 = df_diff[[f'D_{var}' if f'D_{var}' in df_diff.columns else var for var in diff_vars_i1]]\n",
    "X_diff_i1.columns = [f'D_{var}' for var in diff_vars_i1]\n",
    "\n",
    "# Variables I(0) en niveles (efectos contempor√°neos)\n",
    "X_i0_levels = df_aligned[variables_i0]\n",
    "\n",
    "# Variable dependiente: cambio en PIB\n",
    "y_diff = df_diff['log_gdp_brazil']\n",
    "y_diff.name = 'D_log_gdp_brazil'\n",
    "\n",
    "# Combinar todas las variables explicativas\n",
    "X_ecm_ampliado = pd.concat([\n",
    "    ect_lag1,                              # Correcci√≥n de error I(1)\n",
    "    X_diff_i1,                             # Diferencias de variables I(1)  \n",
    "    X_i0_levels,                           # Niveles de variables I(0)\n",
    "    df_aligned['pandemia_dummy']           # Variable dummy\n",
    "], axis=1).dropna()\n",
    "\n",
    "# Alinear variable dependiente\n",
    "y_ecm_ampliado = y_diff.loc[X_ecm_ampliado.index]\n",
    "\n",
    "# Verificar datos\n",
    "print(f\"Observaciones para ECM ampliado: {len(X_ecm_ampliado)}\")\n",
    "print(f\"Variables explicativas: {list(X_ecm_ampliado.columns)}\")\n",
    "\n",
    "# --- PASO 3: ESTIMACI√ìN DEL MODELO AMPLIADO ---\n",
    "print(f\"\\nüéØ PASO 3: ESTIMACI√ìN DEL ECM AMPLIADO\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Estimar modelo\n",
    "modelo_ecm_ampliado = OLS(y_ecm_ampliado, X_ecm_ampliado).fit()\n",
    "\n",
    "print(f\"‚úÖ Modelo de Correcci√≥n de Error Ampliado:\")\n",
    "print(f\"   R¬≤ = {modelo_ecm_ampliado.rsquared:.4f}\")\n",
    "print(f\"   R¬≤ Ajustado = {modelo_ecm_ampliado.rsquared_adj:.4f}\")\n",
    "print(f\"   Observaciones: {modelo_ecm_ampliado.nobs}\")\n",
    "print(f\"   F-statistic: {modelo_ecm_ampliado.fvalue:.2f} (p={modelo_ecm_ampliado.f_pvalue:.4f})\")\n",
    "\n",
    "print(f\"\\nüîß COEFICIENTES DEL MODELO AMPLIADO:\")\n",
    "for var, coef, pval, stderr in zip(X_ecm_ampliado.columns, \n",
    "                                  modelo_ecm_ampliado.params,\n",
    "                                  modelo_ecm_ampliado.pvalues,\n",
    "                                  modelo_ecm_ampliado.bse):\n",
    "    sig = \"***\" if pval < 0.01 else \"**\" if pval < 0.05 else \"*\" if pval < 0.10 else \"\"\n",
    "    \n",
    "    if var == 'ECT_lag1':\n",
    "        print(f\"   Œ± (Correcci√≥n Error I(1)): {coef:.4f} {sig} (se={stderr:.4f})\")\n",
    "        if coef < 0:\n",
    "            print(f\"      ‚úÖ Negativo - Ajuste hacia equilibrio de largo plazo\")\n",
    "            print(f\"      üìà Velocidad: {abs(coef)*100:.1f}% por trimestre\")\n",
    "    elif var.startswith('D_'):\n",
    "        print(f\"   Œ≥ ({var}): {coef:.4f} {sig} (se={stderr:.4f}) [Efecto corto plazo]\")\n",
    "    elif var in variables_i0:\n",
    "        print(f\"   Œ≤ ({var}): {coef:.4f} {sig} (se={stderr:.4f}) [Variable I(0)]\")\n",
    "    elif var == 'pandemia_dummy':\n",
    "        print(f\"   Œ¥ (Pandemia): {coef:.4f} {sig} (se={stderr:.4f})\")\n",
    "\n",
    "# --- PASO 4: COMPARACI√ìN DE MODELOS ---\n",
    "print(f\"\\nüìä PASO 4: COMPARACI√ìN DE ESPECIFICACIONES\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"MODELO ORIGINAL (todas las variables):\")\n",
    "print(f\"  R¬≤ = {modelo_ecm.rsquared:.4f}\")\n",
    "print(f\"  Œ± (correcci√≥n error) = {modelo_ecm.params['ECT_lag1']:.4f}\")\n",
    "\n",
    "print(f\"\\nMODELO CORREGIDO (separando I(1)/I(0)):\")\n",
    "print(f\"  R¬≤ = {modelo_ecm_ampliado.rsquared:.4f}\")\n",
    "print(f\"  Œ± (correcci√≥n error) = {modelo_ecm_ampliado.params['ECT_lag1']:.4f}\")\n",
    "\n",
    "# Mejora en el ajuste\n",
    "mejora_r2 = modelo_ecm_ampliado.rsquared - modelo_ecm.rsquared\n",
    "print(f\"\\nüìà Mejora en R¬≤: {mejora_r2:+.4f}\")\n",
    "\n",
    "if modelo_ecm_ampliado.rsquared > modelo_ecm.rsquared:\n",
    "    print(\"‚úÖ El modelo corregido tiene mejor ajuste\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è El modelo original ten√≠a mejor ajuste\")\n",
    "\n",
    "# --- PASO 5: INTERPRETACI√ìN ECON√ìMICA ---\n",
    "print(f\"\\nüí° PASO 5: INTERPRETACI√ìN ECON√ìMICA CORREGIDA\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"EFECTOS DE LARGO PLAZO (v√≠a cointegraci√≥n I(1)):\")\n",
    "if 'ECT_lag1' in modelo_ecm_ampliado.params.index:\n",
    "    alpha = modelo_ecm_ampliado.params['ECT_lag1'] \n",
    "    if alpha < 0:\n",
    "        print(f\"  ‚úÖ PIB se ajusta {abs(alpha)*100:.1f}% por trimestre hacia equilibrio\")\n",
    "        print(f\"  üìÖ Semivida del shock: ~{np.log(0.5)/np.log(1+alpha):.1f} trimestres\")\n",
    "\n",
    "print(f\"\\nEFECTOS DE CORTO PLAZO:\")\n",
    "for var in X_ecm_ampliado.columns:\n",
    "    if var.startswith('D_') and var in modelo_ecm_ampliado.params.index:\n",
    "        coef = modelo_ecm_ampliado.params[var]\n",
    "        print(f\"  {var}: {coef:.4f} (impacto inmediato)\")\n",
    "\n",
    "print(f\"\\nEFECTOS CONTEMPOR√ÅNEOS (variables I(0)):\")\n",
    "for var in variables_i0:\n",
    "    if var in modelo_ecm_ampliado.params.index:\n",
    "        coef = modelo_ecm_ampliado.params[var]\n",
    "        print(f\"  {var}: {coef:.4f} (efecto en niveles)\")\n",
    "\n",
    "# Guardar resultados corregidos\n",
    "resultados_bid_corregido = {\n",
    "    'modelo_coint': modelo_coint,\n",
    "    'modelo_ecm_ampliado': modelo_ecm_ampliado,\n",
    "    'ect_i1': ect_coint,\n",
    "    'variables_i1': variables_i1,\n",
    "    'variables_i0': variables_i0,\n",
    "    'r2_coint': modelo_coint.rsquared,\n",
    "    'r2_ecm': modelo_ecm_ampliado.rsquared,\n",
    "    'alpha_corregido': modelo_ecm_ampliado.params['ECT_lag1'],\n",
    "    'coint_pvalue': coint_test[1]\n",
    "}\n",
    "\n",
    "print(f\"\\n‚úÖ Modelo BID corregido completado - Resultados en 'resultados_bid_corregido'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
